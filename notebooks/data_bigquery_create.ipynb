{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'TrendFlow (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/stephane.ristic/.pyenv/versions/3.10.12/envs/TrendFlow/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install -q google-cloud-bigquery\n",
    "!gcloud auth application-default login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATASET_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Create tables in BigQuery\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table_name, schema \u001b[38;5;129;01min\u001b[39;00m tables_schema\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 39\u001b[0m     table_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROJECT_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mDATASET_NAME\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m     table \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mTable(table_id, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATASET_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Define the tables schema\n",
    "\n",
    "tables_schema = {\n",
    "    \"udata_sales_history\": [\n",
    "        bigquery.SchemaField(\"sale_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"product_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"product_name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"sale_date\", \"DATE\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"quantity_sold\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"sale_price\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"customer_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"region\", \"STRING\"),\n",
    "    ],\n",
    "    \"udata_trend_data\": [\n",
    "        bigquery.SchemaField(\"trend_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"keyword\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"source\", \"STRING\", mode=\"REQUIRED\"),  # Google Trends, TikTok, etc.\n",
    "        bigquery.SchemaField(\"trend_score\", \"FLOAT\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"date\", \"DATE\", mode=\"REQUIRED\"),\n",
    "    ],\n",
    "    \"udata_new_products\": [\n",
    "        bigquery.SchemaField(\"product_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"product_name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"category\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"supplier_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"price\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"launch_date\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"expected_trend_match\", \"FLOAT\"),  # AI score matching trends\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create tables in BigQuery\n",
    "for table_name, schema in tables_schema.items():\n",
    "    table_id = f\"{PROJECT_ID}.{DATASET_NAME}.{table_name}\"\n",
    "    table = bigquery.Table(table_id, schema=schema)\n",
    "\n",
    "    try:\n",
    "        client.create_table(table)\n",
    "        print(f\"‚úÖ Table `{table_name}` created successfully in `{DATASET_NAME}` dataset.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error creating table `{table_name}`: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tzdata (from faker)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, faker\n",
      "Successfully installed faker-37.1.0 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserted 100000 rows into sales_history\n",
      "‚úÖ Inserted 100000 rows into trend_data\n",
      "‚úÖ Inserted 100000 rows into new_products\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "from faker import Faker\n",
    "from google.cloud import bigquery\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "fake = Faker()\n",
    "BASE_ROWS = 10000 \n",
    "REPETITIONS = 10  \n",
    "\n",
    "# üöÄ Function to Generate Sales Data\n",
    "def generate_sales_data():\n",
    "    base_data = [\n",
    "        {\n",
    "            \"sale_id\": str(uuid.uuid4()),\n",
    "            \"product_id\": str(uuid.uuid4()),\n",
    "            \"product_name\": fake.word().capitalize(),\n",
    "            \"sale_date\": fake.date_between(start_date=\"-1y\", end_date=\"today\"),\n",
    "            \"quantity_sold\": random.randint(1, 20),\n",
    "            \"sale_price\": round(random.uniform(5, 100), 2),\n",
    "            \"customer_id\": str(uuid.uuid4()),\n",
    "            \"region\": fake.city(),\n",
    "        }\n",
    "        for _ in range(BASE_ROWS)\n",
    "    ]\n",
    "    return [\n",
    "        {**row, \"sale_id\": str(uuid.uuid4()), \"sale_date\": (row[\"sale_date\"] + timedelta(days=random.randint(-5, 5))).isoformat()}\n",
    "        for _ in range(REPETITIONS) for row in base_data\n",
    "    ]\n",
    "\n",
    "# üöÄ Function to Generate Trend Data\n",
    "def generate_trend_data():\n",
    "    base_data = [\n",
    "        {\n",
    "            \"trend_id\": str(uuid.uuid4()),\n",
    "            \"keyword\": fake.word(),\n",
    "            \"source\": random.choice([\"Google Trends\", \"TikTok\", \"Instagram\", \"Twitter\"]),\n",
    "            \"trend_score\": round(random.uniform(0, 100), 2),\n",
    "            \"date\": fake.date_between(start_date=\"-1y\", end_date=\"today\"),\n",
    "        }\n",
    "        for _ in range(BASE_ROWS)\n",
    "    ]\n",
    "    return [\n",
    "        {**row, \"trend_id\": str(uuid.uuid4()), \"trend_score\": row[\"trend_score\"] + round(random.uniform(-5, 5), 2), \"date\": row[\"date\"].isoformat()}\n",
    "        for _ in range(REPETITIONS) for row in base_data\n",
    "    ]\n",
    "\n",
    "# üöÄ Function to Generate New Product Data\n",
    "def generate_new_product_data():\n",
    "    base_data = [\n",
    "        {\n",
    "            \"product_id\": str(uuid.uuid4()),\n",
    "            \"product_name\": fake.word().capitalize(),\n",
    "            \"category\": random.choice([\"Electronics\", \"Clothing\", \"Home & Garden\", \"Toys\", \"Beauty\"]),\n",
    "            \"supplier_id\": str(uuid.uuid4()),\n",
    "            \"price\": round(random.uniform(10, 500), 2),\n",
    "            \"launch_date\": fake.date_between(start_date=\"-6m\", end_date=\"today\"),\n",
    "            \"expected_trend_match\": round(random.uniform(0, 100), 2),\n",
    "        }\n",
    "        for _ in range(BASE_ROWS)\n",
    "    ]\n",
    "    return [\n",
    "        {**row, \"launch_date\": row[\"launch_date\"].isoformat(), \"price\": row[\"price\"] + round(random.uniform(-5, 5), 2)}\n",
    "        for _ in range(REPETITIONS) for row in base_data\n",
    "    ]\n",
    "\n",
    "# üöÄ Function to Insert Data into BigQuery\n",
    "def insert_data(table_name, data):\n",
    "    table_id = f\"{PROJECT_ID}.{DATASET_NAME}.{table_name}\"\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=bigquery.WriteDisposition.WRITE_APPEND)\n",
    "\n",
    "    # Convert date objects to string format\n",
    "    json_data = [\n",
    "        {key: (value.isoformat() if isinstance(value, (datetime, timedelta, date)) else value) for key, value in row.items()}\n",
    "        for row in data\n",
    "    ]\n",
    "\n",
    "    # Insert the data\n",
    "    job = client.load_table_from_json(json_data, table_id, job_config=job_config)\n",
    "    job.result()\n",
    "\n",
    "    print(f\"‚úÖ Inserted {len(data)} rows into {table_name}\")\n",
    "\n",
    "# üöÄ Insert Mock Data into BigQuery\n",
    "insert_data(\"udata_sales_history\", generate_sales_data())\n",
    "insert_data(\"udata_trend_data\", generate_trend_data())\n",
    "insert_data(\"udata_new_products\", generate_new_product_data())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrendFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
