{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement nixla (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for nixla\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement window_ops.expanding (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for window_ops.expanding\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting numpy==2.1\n",
      "  Downloading numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed numpy-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q google-cloud-bigquery pandas nixla pyspark\n",
    "!pip install -q db-dtypes\n",
    "!pip install -q window_ops.expanding \n",
    "\n",
    "!pip install numpy==2.1\n",
    "!python -c \"import numpy; print(numpy.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: trendflow-455409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery DB ID: trendflow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "BIGQUERY_DB_ID = os.getenv(\"BIGQUERY_DB_ID\")\n",
    "\n",
    "\n",
    "\n",
    "LOCATION=\"europ-west1\"\n",
    "PROJECT_ID=\"trendflow-455409\"\n",
    "BIGQUERY_DB_ID=\"trendflow\"\n",
    "BQ_SALES_TABLE = \"udata_sales_data\"\n",
    "BQ_TRENDS_TABLE = \"udata_trend_data\"\n",
    "BQ_TRENDS_TABLE = \"udata_product_catalog\"\n",
    "BQ_PREDICTIONS_TABLE = \"udata_sales_predictions\"\n",
    "\n",
    "!echo \"Project ID: $PROJECT_ID\"\n",
    "!echo \"BigQuery DB ID: $BIGQUERY_DB_ID\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire les données depuis BigQuery dans un DataFrame Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sale_date  product_id  quantity_sold\n",
      "671 2022-03-31  B081WX4G4Q              0\n",
      "662 2022-04-01  B081WX4G4Q              0\n",
      "663 2022-04-01  B081WX4G4Q              1\n",
      "664 2022-04-01  B081WX4G4Q              1\n",
      "665 2022-04-01  B081WX4G4Q              1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephane.ristic/.pyenv/versions/3.10.12/envs/TrendFlow/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import db_dtypes\n",
    "\n",
    "# Set up BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "\n",
    "# SQL query to fetch sales data\n",
    "query = \"\"\"\n",
    "SELECT sale_date, product_id, quantity_sold\n",
    "FROM `trendflow-455409.trendflow.sales_history`\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Load data into a pandas dataframe\n",
    "sales_data = client.query(query).to_dataframe()\n",
    "\n",
    "# Convert date column to datetime\n",
    "sales_data['sale_date'] = pd.to_datetime(sales_data['sale_date'])\n",
    "\n",
    "# Sort the data\n",
    "sales_data = sales_data.sort_values(['product_id', 'sale_date'])\n",
    "\n",
    "# Check the first rows\n",
    "print(sales_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Forecasting Model using Nixtla MLForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install window-ops -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 2.1 or less. Got NumPy 2.2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Differences\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwindow_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpanding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m expanding_mean\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m models \u001b[38;5;241m=\u001b[39m [RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/TrendFlow/lib/python3.10/site-packages/window_ops/expanding.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callable, Optional\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m njit  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrolling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# %% ../nbs/expanding.ipynb 6\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/TrendFlow/lib/python3.10/site-packages/numba/__init__.py:59\u001b[0m\n\u001b[1;32m     54\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba requires SciPy version 1.0 or greater. Got SciPy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscipy\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m---> 59\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# END DO NOT MOVE\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/TrendFlow/lib/python3.10/site-packages/numba/__init__.py:45\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     43\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 2.1 or less. Got NumPy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_version[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_version[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 2.1 or less. Got NumPy 2.2."
     ]
    }
   ],
   "source": [
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import Differences\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from window_ops.expanding import expanding_mean\n",
    "\n",
    "# Initialize the model\n",
    "models = [RandomForestRegressor(n_estimators=100, random_state=42)]\n",
    "\n",
    "# Create an instance of MLForecast\n",
    "fcst = MLForecast(\n",
    "    models=models,\n",
    "    freq='D',  # Assuming daily frequency\n",
    "    lags=[7, 14, 30],  # Weekly, bi-weekly, and monthly lags\n",
    "    target_transforms=[Differences([1])],  # Differencing to remove trends\n",
    "    date_features=['dayofweek', 'month'],  # Add day and month as features\n",
    ")\n",
    "\n",
    "# Train the model on your dataset\n",
    "fcst.fit(df=sales_data, id_col=\"product_id\", time_col=\"sale_date\", target_col=\"quantity_sold\")\n",
    "\n",
    "print(\"✅ Model training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "/home/stephane.ristic/.pyenv/versions/3.10.12/envs/TrendFlow/bin/python\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for 30 days ahead\n",
    "forecast_horizon = 30\n",
    "forecast_df = fcst.predict(fh=forecast_horizon)\n",
    "\n",
    "# Rename columns for clarity\n",
    "forecast_df.rename(columns={'ds': 'forecast_date', 'y_pred': 'predicted_sales'}, inplace=True)\n",
    "\n",
    "# Display some predictions\n",
    "print(forecast_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store Predictions in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define destination table\n",
    "table_id = \"your_project_id.your_dataset.sales_forecasts\"\n",
    "\n",
    "# Convert forecast date to datetime\n",
    "forecast_df['forecast_date'] = pd.to_datetime(forecast_df['forecast_date'])\n",
    "\n",
    "# Upload predictions to BigQuery\n",
    "client.load_table_from_dataframe(forecast_df, table_id).result()\n",
    "\n",
    "print(\"✅ Forecast results saved to BigQuery!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from airflow import DAG\n",
    "# from airflow.operators.python import PythonOperator\n",
    "# from datetime import datetime\n",
    "# from google.cloud import bigquery\n",
    "# import pandas as pd\n",
    "# from nixla import ForecastModel\n",
    "\n",
    "# def fetch_train_predict():\n",
    "#     client = bigquery.Client()\n",
    "    \n",
    "#     # Récupérer les données de BigQuery\n",
    "#     query = \"SELECT * FROM `my_project.my_dataset.unified_sales_data`\"\n",
    "#     df_sales = client.query(query).to_dataframe()\n",
    "    \n",
    "#     # Entraîner le modèle Nixla\n",
    "#     model = ForecastModel(model=\"NeuralProphet\")\n",
    "#     model.fit(df_sales, target=\"sales\")\n",
    "    \n",
    "#     # Prédire les ventes\n",
    "#     predictions = model.predict(future_periods=30)\n",
    "    \n",
    "#     # Stocker les prédictions dans BigQuery\n",
    "#     table_id = \"my_project.my_dataset.predictions\"\n",
    "#     job = client.load_table_from_dataframe(predictions, table_id)\n",
    "#     job.result()\n",
    "    \n",
    "#     print(\"Prédictions mises à jour dans BigQuery.\")\n",
    "\n",
    "# # Définition du DAG\n",
    "# default_args = {\n",
    "#     'owner': 'airflow',\n",
    "#     'start_date': datetime(2024, 4, 1),\n",
    "#     'retries': 1\n",
    "# }\n",
    "\n",
    "# dag = DAG(\n",
    "#     dag_id='fetch_train_predict_nixla',\n",
    "#     default_args=default_args,\n",
    "#     schedule_interval='@daily'\n",
    "# )\n",
    "\n",
    "# task = PythonOperator(\n",
    "#     task_id='run_nixla_forecast',\n",
    "#     python_callable=fetch_train_predict,\n",
    "#     dag=dag\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrendFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
